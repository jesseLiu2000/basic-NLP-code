{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM4USocTYCrv9BeisDerMdH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L2csIVa16gBg","executionInfo":{"status":"ok","timestamp":1677753919755,"user_tz":360,"elapsed":143783,"user":{"displayName":"Jesse Liu","userId":"09638298407322875956"}},"outputId":"61248020-a420-4ea8-d69f-991088651aa2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 1000 cost = 0.002546\n","Epoch: 2000 cost = 0.000730\n","Epoch: 3000 cost = 0.000323\n","Epoch: 4000 cost = 0.000165\n","Epoch: 5000 cost = 0.000091\n","woww\n","whitw\n"]}],"source":["# jesseLiu2000\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","from tkinter import _flatten\n","\n","\n","class Seq2Seq(nn.Module):\n","    def __init__(self):\n","        super(Seq2Seq, self).__init__()\n","        self.embedding = nn.Embedding(n_seq, embedding_size)\n","        self.encoder = nn.RNN(input_size=embedding_size, hidden_size=hidden_size, num_layers=6, dropout=0.1)\n","        self.decoder = nn.RNN(input_size=embedding_size, hidden_size=hidden_size, num_layers=6, dropout=0.1)\n","        self.fc1 = nn.Linear(hidden_size, n_seq)\n","\n","    def forward(self, encoder_input, hidden_state, decoder_input):\n","        encoder_embedding = self.embedding(encoder_input) # [batch_size, seq_length, embedding_size]\n","        encoder_embedding = encoder_embedding.permute(1, 0, 2) # [seq_length, batch_size, embedding_size]\n","        decoder_embedding = self.embedding(decoder_input)\n","        decoder_embedding = decoder_embedding.permute(1, 0, 2)\n","\n","        _, encoder_output = self.encoder(encoder_embedding, hidden_state) # [num_layers * num_directions, batch_size, hidden_size]\n","        decoder_output, _ = self.decoder(decoder_embedding, encoder_output) # [max_seq_length, batch_size, num_directions * hidden_size]\n","\n","        output = self.fc1(decoder_output) # [max_seq_length, batch_size, n_class]\n","        return output\n","\n","\n","\n","if __name__ == '__main__':\n","    max_length = 7\n","\n","    alphabet = [c for c in 'SEPabcdefghijklmnopqrstuvwxyz']\n","    word2index = {w: i for i, w in enumerate(alphabet)}\n","    index2word = {i: w for i, w in enumerate(alphabet)}\n","    file_lst = [['man', 'women'], ['black', 'white'], ['king', 'queen'], ['girl', 'boy'], ['up', 'down'],\n","                ['high', 'low']]\n","\n","    # [batch_size, seg_length]\n","    en_input = [[word2index[word] for word in (sent[0]+(\"P\"*(max_length-len(sent[0]))))] for sent in file_lst]\n","    de_input = [[word2index[word] for word in (('S'+sent[1])+(\"P\"*(max_length-len('S'+sent[1]))))] for sent in file_lst]\n","    targets = [[word2index[word] for word in (sent[1]+(\"P\"*(max_length-len(sent[1]+'E')))+'E')] for sent in file_lst]\n","    en_input = torch.LongTensor(en_input)\n","    de_input = torch.LongTensor(de_input)\n","    targets = torch.LongTensor(targets)\n","    state = None\n","\n","    n_seq = len(word2index)\n","    batch_size = len(file_lst)\n","    embedding_size = 64\n","    hidden_size = 128\n","\n","    lr = 1e-3\n","    epoch = 5000\n","\n","    model = Seq2Seq()\n","    optimizer = optim.Adam(model.parameters(), lr=lr)\n","    criterion = nn.CrossEntropyLoss()\n","\n","    #Train\n","    for ep in range(epoch):\n","        optimizer.zero_grad()\n","\n","        output = model(en_input, state, de_input)\n","        output = output.permute(1, 0, 2) # [batch_size, max_seq_length, n_class]\n","        # print(output.size())\n","        # print(targets.size())\n","        loss = 0\n","        for i in range(len(targets)):\n","            loss += criterion(output[i], targets[i])\n","\n","        if (ep + 1) % 1000 == 0:\n","            print('Epoch:', '%04d' % (ep + 1), 'cost =', '{:.6f}'.format(loss))\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","    #Test\n","    test_lst = ['men', 'black']\n","    state = None\n","    de_input = torch.LongTensor([[0, 2, 2, 2, 2, 2, 2], [0, 2, 2, 2, 2, 2, 2]])\n","    en_input = [[word2index[word] for word in (sent+(max_length-len(sent))*'P')] for sent in test_lst]\n","    en_input = torch.LongTensor(en_input)\n","    output = model(en_input, state, de_input)\n","    predict = output.data.max(2, keepdim=True)[1]\n","    # map_pre = [alphabet[i] for i in predict]\n","    predict = predict.permute(1, 0, 2)\n","    for i in range(len(predict)):\n","        pre_str = [index2word[int(lt)] for word in predict[i] for lt in word ]\n","        # pre_str = _flatten(pre_str)\n","        pre_str = ''.join(pre_str)\n","        print(pre_str.replace('E','').replace('P', ''))\n","\n","\n","\n","\n"]}]}